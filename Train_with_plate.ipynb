{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3719a8c-5196-4712-94a7-cd389830ab8f",
   "metadata": {},
   "source": [
    "# MobileNetv2-Based Model\n",
    "This script is the implementation of a MobileNetV2-based model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3f0abb-b5e5-44f0-acdf-876c88f9fd8a",
   "metadata": {},
   "source": [
    "### Image Metadata Preprocessing\n",
    "This code in the cell below loads all `.png` files from the dataset, extracts metadata (row, column, field, plane, channel, cell number, plate ID, and source), and maps columns to biological class labels. \n",
    "\n",
    "It then removes invalid entries, sorts the dataset for consistency, and creates a structured DataFrame (`img_path_pd`) for later usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa9ac2c-a591-482a-b91b-5e53d3604d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import platform\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "print('Python =', platform.python_version())\n",
    "print('TensorFlow =', tf.__version__)\n",
    "\n",
    "NUM_GPU = 4\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3'\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "CODE_FOLDER_NAME = 'codes'\n",
    "\n",
    "FOLDER = 'home/featurize'\n",
    "\n",
    "# Base path to the processed image dataset \n",
    "BASE_PATH = 'home/featurize/F1_balanced'\n",
    "\n",
    "# Recursively get all .png file paths\n",
    "all_png_paths = list(Path(BASE_PATH).rglob('*.png'))\n",
    "img_path_pd = pd.DataFrame(all_png_paths, columns=['path']).astype(str)\n",
    "\n",
    "# Extract base filename (no extension)\n",
    "img_path_pd['filename'] = img_path_pd['path'].apply(lambda x: os.path.splitext(os.path.basename(x))[0])\n",
    "\n",
    "# Save subfolder path\n",
    "img_path_pd['folder'] = img_path_pd['path'].apply(lambda x: str(Path(x).parent))\n",
    "\n",
    "# Extract \"front\" identifier (before \"-chX...\")\n",
    "# This will give r02c02f01p03-\n",
    "img_path_pd['front'] = img_path_pd['filename'].apply(lambda x: x.split('-')[0] + '-')\n",
    "\n",
    "# Parse metadata from filename\n",
    "img_path_pd['row']     = img_path_pd['filename'].str[0:3]    # e.g., r02\n",
    "img_path_pd['column']  = img_path_pd['filename'].str[3:6]    # e.g., c02\n",
    "img_path_pd['field']   = img_path_pd['filename'].str[6:9]    # e.g., f01\n",
    "img_path_pd['plane']   = img_path_pd['filename'].str[9:12]   # e.g., p03\n",
    "img_path_pd['channel'] = img_path_pd['filename'].str.split('-').str[1].str[:3]  # ch1\n",
    "img_path_pd['rcf']     = img_path_pd['row'] + img_path_pd['column'] + img_path_pd['field']\n",
    "img_path_pd['rc']      = img_path_pd['row'] + img_path_pd['column']\n",
    "\n",
    "# Extract cell number \n",
    "img_path_pd['cell_no_str'] = img_path_pd['filename'].str.extract(r'_Cell_(\\d{1,3})')[0]\n",
    "\n",
    "# Extract plate_id from filename (_P1, _P2, _P3)\n",
    "# img_path_pd['plate_id'] = img_path_pd['filename'].str.extract(r'_P(\\d)$')[0].astype(int)\n",
    "img_path_pd['plate_id'] = img_path_pd['filename'].str.extract(r'_P(\\d)_F\\d')[0].astype(int)\n",
    "\n",
    "# For all the dataset, add this part to extract data sources (F1, F2, F3)\n",
    "img_path_pd['source'] = img_path_pd['filename'].str.extract(r'_F(\\d)$')[0].astype(int)\n",
    "\n",
    "# Convert column string to integer\n",
    "img_path_pd['column_id'] = img_path_pd['column'].str[1:].astype(int)\n",
    "\n",
    "# Map labels based on column number\n",
    "column_label_map = {\n",
    "    2: 'PARENT',\n",
    "    3: 'TREM2_KO',\n",
    "    4: 'R47H',\n",
    "    5: 'H157Y',\n",
    "    6: 'PLCG2_KO',\n",
    "    7: 'P522R',\n",
    "    8: 'P522R_HET',\n",
    "    9: 'SHIP1_KO',\n",
    "    10: 'ABI3_KO',\n",
    "    11: 'S209F'\n",
    "}\n",
    "img_path_pd['class_name'] = img_path_pd['column_id'].map(column_label_map)\n",
    "\n",
    "# Drop invalid rows\n",
    "img_path_pd = img_path_pd.dropna(subset=['class_name']).reset_index(drop=True)\n",
    "\n",
    "# Sort for consistency\n",
    "# img_path_pd = img_path_pd.sort_values(by=['rcf', 'plane', 'channel']).reset_index(drop=True)\n",
    "img_path_pd = img_path_pd.sort_values(by=['rcf', 'plane', 'channel', 'source']).reset_index(drop=True)\n",
    "\n",
    "# Output preview\n",
    "print(img_path_pd.shape)\n",
    "img_path_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beae5f15-0d13-4668-b9b3-0ecf5f0d02ba",
   "metadata": {},
   "source": [
    "### Cell-Level Grouping and Train/Validation Split\n",
    "This code assigns numerical labels to classes based on a fixed order, constructs a unique `cell_id` (combining position, cell number, and plate ID) to represent each 5-channel image group, and filters out incomplete cells. \n",
    "\n",
    "It then ensures one label per cell, stratifies by class, and splits the dataset into training and validation sets at the **cell level** to avoid data leakage.\n",
    "\n",
    "Finally, it retrieves all 5-channel image paths for each split and checks the label distribution to confirm balanced sampling across classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862d9bd8-55ea-44ce-a624-ddfcb83a9180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# control the label order\n",
    "custom_label_order = [\n",
    "    'PARENT', 'TREM2_KO', 'R47H', 'H157Y', 'PLCG2_KO',\n",
    "    'P522R', 'P522R_HET', 'SHIP1_KO', 'ABI3_KO', 'S209F'\n",
    "]\n",
    "\n",
    "# create name â†’ index mapping\n",
    "label2id = {name: idx for idx, name in enumerate(custom_label_order)}\n",
    "\n",
    "# Add a numerical label to the DataFrame\n",
    "img_path_pd['label'] = img_path_pd['class_name'].map(label2id)\n",
    "print('Custom label mapping: ', label2id)\n",
    "\n",
    "# Add a cell_id column (including plate information, used to represent a 5-channel image group)\n",
    "# Create a unique cell_id using front + cell_no_str + plate_id\n",
    "img_path_pd['cell_id'] = (\n",
    "    img_path_pd['front'] + \n",
    "    'Cell_' + img_path_pd['cell_no_str'] + \n",
    "    '_P' + img_path_pd['plate_id'].astype(str)\n",
    ")\n",
    "\n",
    "#img_path_pd['cell_id'] = (\n",
    "#    img_path_pd['front'] + \n",
    "#    'Cell_' + img_path_pd['cell_no_str'] + \n",
    "#    '_P' + img_path_pd['plate_id'].astype(str) +\n",
    "#    '_F' + img_path_pd['source'].astype(str)\n",
    "#)\n",
    "\n",
    "# Check whether each cell has all 5 channels\n",
    "cell_channel_counts = img_path_pd.groupby('cell_id')['channel'].count()\n",
    "print(f\"Cells with 5 channels: {(cell_channel_counts == 5).sum()}\")\n",
    "print(f\"Cells with incomplete channels: {(cell_channel_counts != 5).sum()}\")\n",
    "\n",
    "# Keep only cells with complete 5 channels\n",
    "complete_cells = cell_channel_counts[cell_channel_counts == 5].index\n",
    "img_path_pd_filtered = img_path_pd[img_path_pd['cell_id'].isin(complete_cells)].reset_index(drop=True)\n",
    "\n",
    "print(f\"Original cells: {img_path_pd['cell_id'].nunique()}\")\n",
    "print(f\"Complete cells: {len(complete_cells)}\")\n",
    "\n",
    "# Deduplicate based on cell_id, and create a label mapping for each cell (use any one image to represent a cell)\n",
    "cell_df = img_path_pd_filtered.drop_duplicates('cell_id')[['cell_id', 'label']]\n",
    "\n",
    "print(f\"Unique cells for splitting: {len(cell_df)}\")\n",
    "print(\"Label distribution:\")\n",
    "print(cell_df['label'].value_counts().sort_index())\n",
    "\n",
    "# Split the dataset by cells (to avoid images from the same cell being mixed in both training and validation sets)\n",
    "train_cell_ids, val_cell_ids = train_test_split(\n",
    "    cell_df['cell_id'],\n",
    "    test_size=0.2,\n",
    "    random_state=1,\n",
    "    stratify=cell_df['label']\n",
    ")\n",
    "#cell_df['stratify_col'] = cell_df['label'].astype(str) + '_' + cell_df['cell_id'].str.extract(r'_F(\\d)$')[0]\n",
    "#train_cell_ids, val_cell_ids = train_test_split(\n",
    "#    cell_df['cell_id'],\n",
    "#    test_size=0.2,\n",
    "#    random_state=1,\n",
    "#    stratify=cell_df['stratify_col']\n",
    "#)\n",
    "\n",
    "# Retrieve the complete 5-channel image paths corresponding to each cell (image-level data)\n",
    "pl_train_pd = img_path_pd_filtered[img_path_pd_filtered['cell_id'].isin(train_cell_ids)].reset_index(drop=True)\n",
    "pl_val_pd = img_path_pd_filtered[img_path_pd_filtered['cell_id'].isin(val_cell_ids)].reset_index(drop=True)\n",
    "\n",
    "print(f'Training size: {pl_train_pd.shape}')\n",
    "print(f'Validation size: {pl_val_pd.shape}')\n",
    "print(f'Training unique cells: {pl_train_pd[\"cell_id\"].nunique()}')\n",
    "print(f'Validation unique cells: {pl_val_pd[\"cell_id\"].nunique()}')\n",
    "\n",
    "# Check the label distribution in the training and validation sets\n",
    "print(\"\\nTraining set label distribution:\")\n",
    "train_label_counts = pl_train_pd.drop_duplicates('cell_id')['label'].value_counts().sort_index()\n",
    "for label, count in train_label_counts.items():\n",
    "    class_name = [k for k, v in label2id.items() if v == label][0]\n",
    "    print(f\"  {class_name} (label {label}): {count} cells\")\n",
    "\n",
    "print(\"\\nValidation set label distribution:\")\n",
    "val_label_counts = pl_val_pd.drop_duplicates('cell_id')['label'].value_counts().sort_index()\n",
    "for label, count in val_label_counts.items():\n",
    "    class_name = [k for k, v in label2id.items() if v == label][0]\n",
    "    print(f\"  {class_name} (label {label}): {count} cells\")\n",
    "\n",
    "pl_train_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b27a5a-a3fc-422e-b837-62adcd240efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Root path where PNG images are stored\n",
    "BASE_PATH = 'All'\n",
    "\n",
    "# Ensure consistent channel order\n",
    "channel_order = sorted(img_path_pd['channel'].unique())  # e.g., ['ch1', 'ch2', ..., 'ch5']\n",
    "\n",
    "# If we're working with cell-level splits, we need to get unique cells for training and validation\n",
    "# Get unique cell identifiers and their corresponding labels from the split data\n",
    "train_cell_info = pl_train_pd.drop_duplicates('cell_id')[['cell_id', 'front', 'cell_no_str', 'plate_id', 'label']]\n",
    "val_cell_info = pl_val_pd.drop_duplicates('cell_id')[['cell_id', 'front', 'cell_no_str', 'plate_id', 'label']]\n",
    "\n",
    "# For all dataset:\n",
    "#train_cell_info = pl_train_pd.drop_duplicates('cell_id')[['cell_id', 'front', 'cell_no_str', 'plate_id', 'source', 'label']]\n",
    "#val_cell_info = pl_val_pd.drop_duplicates('cell_id')[['cell_id', 'front', 'cell_no_str', 'plate_id', 'source', 'label']]\n",
    "\n",
    "# Convert to numpy arrays for dataset creation\n",
    "train_fronts = train_cell_info['front'].to_numpy()\n",
    "train_cells = train_cell_info['cell_no_str'].to_numpy()\n",
    "train_plates = train_cell_info['plate_id'].astype(str).to_numpy()\n",
    "train_labels = train_cell_info['label'].to_numpy()\n",
    "# add for all\n",
    "#train_sources = train_cell_info['source'].astype(str).to_numpy()\n",
    "\n",
    "val_fronts = val_cell_info['front'].to_numpy() \n",
    "val_cells = val_cell_info['cell_no_str'].to_numpy()\n",
    "val_plates = val_cell_info['plate_id'].astype(str).to_numpy()\n",
    "val_labels = val_cell_info['label'].to_numpy()\n",
    "# add for all\n",
    "#val_sources = val_cell_info['source'].astype(str).to_numpy()\n",
    "\n",
    "# Function to load and stack 5-channel images\n",
    "#def stack_img(front, cell_no_str, plate_id, label):\n",
    "\n",
    "def stack_img(front, cell_no_str, plate_id, source, label):\n",
    "    img_list = []\n",
    "    for ch in channel_order:\n",
    "        # Updated folder path construction for F1_balanced dataset\n",
    "        # Path structure: .../front+ch+sk1fk1fl1/front+ch+sk1fk1fl1_Cell_X_PY.png\n",
    "        folder = tf.strings.join([BASE_PATH, '/', front, ch, 'sk1fk1fl1'])\n",
    "        filename = tf.strings.join([front, ch, 'sk1fk1fl1_Cell_', cell_no_str, '_P', plate_id, '.png'])\n",
    "        #filename = tf.strings.join([front, ch, 'sk1fk1fl1_Cell_', cell_no_str, '_P', plate_id, '_F', source, '.png'])\n",
    "        full_path = tf.strings.join([folder, '/', filename])\n",
    "        \n",
    "        # Read and normalize the image\n",
    "        img = tf.io.decode_png(tf.io.read_file(full_path), channels=1)\n",
    "        img = tf.cast(img, tf.float32) / 127.5 - 1.0\n",
    "        img_list.append(img)\n",
    "    \n",
    "    img_stack = tf.concat(img_list, axis=-1)  # shape: (H, W, 5)\n",
    "    return img_stack, label\n",
    "\n",
    "# Batch size\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Build the training dataset\n",
    "#train_ds = tf.data.Dataset.from_tensor_slices((train_fronts, train_cells, train_plates, train_labels))\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_fronts, train_cells, train_plates, train_sources, train_labels))\n",
    "train_batches = (train_ds\n",
    "    .shuffle(buffer_size=len(train_fronts), reshuffle_each_iteration=True)\n",
    "    .map(stack_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "# Build the validation dataset  \n",
    "val_ds = tf.data.Dataset.from_tensor_slices((val_fronts, val_cells, val_plates, val_labels))\n",
    "#val_ds = tf.data.Dataset.from_tensor_slices((val_fronts, val_cells, val_plates, val_sources, val_labels))\n",
    "val_batches = (val_ds\n",
    "    .map(stack_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "print(f\"Training cells: {len(train_fronts)}\")\n",
    "print(f\"Validation cells: {len(val_fronts)}\")\n",
    "\n",
    "# Visualise a batch\n",
    "for images, labels in train_batches.take(1):\n",
    "    sample_image = images[0]\n",
    "    sample_label = labels[0].numpy()\n",
    "    \n",
    "    print(f\"Label index: {sample_label}\")\n",
    "    print(f\"Image shape: {sample_image.shape}\")\n",
    "    print(f\"Pixel range: min={tf.reduce_min(sample_image).numpy():.2f}, max={tf.reduce_max(sample_image).numpy():.2f}\")\n",
    "    \n",
    "    id2label = {v: k for k, v in label2id.items()}\n",
    "    label_name = id2label[sample_label]\n",
    "    print(f\"Label name: {label_name}\")\n",
    "    \n",
    "    # Plot the 5 channels\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    for i in range(sample_image.shape[-1]):\n",
    "        plt.subplot(1, sample_image.shape[-1], i + 1)\n",
    "        plt.imshow(sample_image[:, :, i], cmap='gray')\n",
    "        plt.title(f\"Channel {i + 1}\")\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(f\"Sample Image - Label: {sample_label} â†’ {label_name}\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542967e9-db5f-40f5-8921-77efa262f4f2",
   "metadata": {},
   "source": [
    "### (Optional) Overlapping Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bacdad9-e32b-4a21-85b8-e91f73b39b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def check_cell_level_overlap(pl_train_pd, pl_val_pd):\n",
    "    \"\"\"\n",
    "    Focused cell-level overlap verification\n",
    "    \"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"CELL-LEVEL OVERLAP CHECK\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Get unique cell_ids from each set\n",
    "    train_cells = set(pl_train_pd['cell_id'].unique())\n",
    "    val_cells = set(pl_val_pd['cell_id'].unique())\n",
    "    \n",
    "    # Find overlaps\n",
    "    cell_overlap = train_cells.intersection(val_cells)\n",
    "    \n",
    "    # Basic stats\n",
    "    print(f\"Training unique cells: {len(train_cells)}\")\n",
    "    print(f\"Validation unique cells: {len(val_cells)}\")\n",
    "    print(f\"Total unique cells: {len(train_cells) + len(val_cells)}\")\n",
    "    print(f\"Overlapping cells: {len(cell_overlap)}\")\n",
    "    \n",
    "    # Check ratios\n",
    "    total_original = len(pd.concat([pl_train_pd, pl_val_pd])['cell_id'].unique())\n",
    "    train_ratio = len(train_cells) / total_original\n",
    "    val_ratio = len(val_cells) / total_original\n",
    "    \n",
    "    print(f\"\\nSplit ratios:\")\n",
    "    print(f\"  Training: {train_ratio:.1%}\")\n",
    "    print(f\"  Validation: {val_ratio:.1%}\")\n",
    "    \n",
    "    # Overlap result\n",
    "    print(f\"\\n{'='*20} RESULT {'='*20}\")\n",
    "    if len(cell_overlap) == 0:\n",
    "        print(\" SUCCESS: No cell overlap found!\")\n",
    "        print(\"   Data split is clean - no risk of data leakage\")\n",
    "    else:\n",
    "        print(f\" PROBLEM: Found {len(cell_overlap)} overlapping cells!\")\n",
    "        print(\"   This indicates data leakage risk\")\n",
    "        \n",
    "        # Show some examples of overlapping cells\n",
    "        overlap_examples = list(cell_overlap)[:10]\n",
    "        print(f\"   Examples of overlapping cell_ids:\")\n",
    "        for cell_id in overlap_examples:\n",
    "            print(f\"     - {cell_id}\")\n",
    "        \n",
    "        if len(cell_overlap) > 10:\n",
    "            print(f\"     ... and {len(cell_overlap) - 10} more\")\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    return len(cell_overlap) == 0\n",
    "\n",
    "# Run the cell-level check\n",
    "is_clean = check_cell_level_overlap(pl_train_pd, pl_val_pd)\n",
    "\n",
    "# Additional verification: check if all original cells are accounted for\n",
    "print(f\"\\nVERIFICATION:\")\n",
    "original_cells = set(img_path_pd_filtered['cell_id'].unique())  \n",
    "all_split_cells = set(pl_train_pd['cell_id'].unique()).union(set(pl_val_pd['cell_id'].unique()))\n",
    "\n",
    "missing_cells = original_cells - all_split_cells\n",
    "extra_cells = all_split_cells - original_cells\n",
    "\n",
    "print(f\"Original total cells: {len(original_cells)}\")\n",
    "print(f\"Cells after split: {len(all_split_cells)}\")\n",
    "print(f\"Missing cells: {len(missing_cells)}\")\n",
    "print(f\"Extra cells: {len(extra_cells)}\")\n",
    "\n",
    "if len(missing_cells) == 0 and len(extra_cells) == 0:\n",
    "    print(\" All original cells are properly accounted for\")\n",
    "else:\n",
    "    if len(missing_cells) > 0:\n",
    "        print(f\" {len(missing_cells)} cells are missing after split\")\n",
    "        if len(missing_cells) <= 10:\n",
    "            print(\"Missing cells:\")\n",
    "            for cell_id in missing_cells:\n",
    "                print(f\"  - {cell_id}\")\n",
    "    if len(extra_cells) > 0:\n",
    "        print(f\" {len(extra_cells)} extra cells appeared after split\")\n",
    "        if len(extra_cells) <= 10:\n",
    "            print(\"Extra cells:\")\n",
    "            for cell_id in extra_cells:\n",
    "                print(f\"  - {cell_id}\")\n",
    "\n",
    "# Additional check: verify split maintains label distribution\n",
    "print(f\"\\n{'='*20} LABEL DISTRIBUTION CHECK {'='*20}\")\n",
    "print(\"Training set label distribution:\")\n",
    "train_label_counts = pl_train_pd.drop_duplicates('cell_id')['label'].value_counts().sort_index()\n",
    "for label, count in train_label_counts.items():\n",
    "    print(f\"  Label {label}: {count} cells\")\n",
    "\n",
    "print(\"\\nValidation set label distribution:\")\n",
    "val_label_counts = pl_val_pd.drop_duplicates('cell_id')['label'].value_counts().sort_index()\n",
    "for label, count in val_label_counts.items():\n",
    "    print(f\"  Label {label}: {count} cells\")\n",
    "\n",
    "# Check if split is stratified correctly\n",
    "print(f\"\\nStratification check:\")\n",
    "all_cells = len(original_cells)\n",
    "for label in sorted(train_label_counts.index.union(val_label_counts.index)):\n",
    "    train_count = train_label_counts.get(label, 0)\n",
    "    val_count = val_label_counts.get(label, 0)\n",
    "    total_count = train_count + val_count\n",
    "    train_pct = train_count / total_count * 100 if total_count > 0 else 0\n",
    "    val_pct = val_count / total_count * 100 if total_count > 0 else 0\n",
    "    print(f\"  Label {label}: Train {train_pct:.1f}% ({train_count}), Val {val_pct:.1f}% ({val_count})\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c75578-bc8f-4d78-ba59-a39e737545d7",
   "metadata": {},
   "source": [
    "### Build and Train the MobileNetv2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ea9601-25fe-488a-91a3-b71e57061ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "IMG_HEIGHT = 540\n",
    "IMG_WIDTH = 540\n",
    "EPOCH_INITIAL = 25\n",
    "BASE_LEARNING_RATE = 0.002\n",
    "GLOBAL_BATCH_SIZE = BATCH_SIZE  \n",
    "\n",
    "# Multi GPU training\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "with strategy.scope():\n",
    "\n",
    "    # Builds a MobileNetV2 that accepts 5-channel input.\n",
    "    base_model = tf.keras.applications.MobileNetV2(input_shape=(IMG_HEIGHT, IMG_WIDTH, len(channel_order)),\n",
    "                                                   include_top=False,\n",
    "                                                   weights=None)\n",
    "\n",
    "    # Loads a pretrained MobileNetV2 (3-channel).\n",
    "    #base_weights = tf.keras.applications.MobileNetV2(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n",
    "                                                     #include_top=False,\n",
    "                                                     #weights='imagenet')\n",
    "\n",
    "    local_weights_path = '/home/featurize/work/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5'\n",
    "\n",
    "    base_weights = tf.keras.applications.MobileNetV2(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n",
    "                                                 include_top=False,\n",
    "                                                 weights=local_weights_path)\n",
    "    \n",
    "    copy_weight_from = 2\n",
    "    # layers 0 and 1 are NOT copied\n",
    "    # This is because the first convolutional layer expects 3 channels (ImageNet) \n",
    "    # but your model has 5 channels\n",
    "    \n",
    "    for i in range(copy_weight_from, len(base_model.layers)):\n",
    "        base_model.layers[i].set_weights(base_weights.layers[i].get_weights())\n",
    "    for layer in base_model.layers[copy_weight_from:]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    print(\"Number of layers in the base model: \", len(base_model.layers))\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH, len(channel_order)))\n",
    "    _ = inputs  # images have already been normalized, so no further preprocessing is needed.\n",
    "\n",
    "    _ = base_model(_, training=False)  # freeze batch_norm\n",
    "    _ = tf.keras.layers.MaxPool2D(pool_size=2)(_)\n",
    "\n",
    "    _ = tf.keras.layers.GlobalAveragePooling2D()(_)\n",
    "    \n",
    "    #Applies Dropout (20%) to prevent overfitting\n",
    "    _ = tf.keras.layers.Dropout(0.2)(_)\n",
    "\n",
    "    # Final classification layer with 10 output neurons (for 10 classes), \n",
    "    # using softmax to output class probabilities\n",
    "    outputs = tf.keras.layers.Dense(10, activation='softmax')(_)  \n",
    "\n",
    "    # Wraps the defined layers into a Model object.\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=BASE_LEARNING_RATE),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    model.summary(line_length=120)\n",
    "\n",
    "# defines an EarlyStopping callback\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    verbose=1,\n",
    "    patience=80,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)\n",
    "\n",
    "\n",
    "# path = os.path.join('/Users/zhuangzhuang/Desktop/Data Science Project/baseline_datasets', CODE_FOLDER_NAME, FOLDER)\n",
    "path = os.path.join('work', CODE_FOLDER_NAME, FOLDER)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "csv_logger = tf.keras.callbacks.CSVLogger(os.path.join(path, 'log_initial_{}.csv'.format(FOLDER)), append=False)\n",
    "\n",
    "    \n",
    "class save_per_epoch(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super(save_per_epoch, self).__init__()\n",
    "        self.verbose = verbose\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.model.save(os.path.join(path, 'model_temp_{}_{}.h5'.format(FOLDER, epoch)))\n",
    "\n",
    "class validate_all_val(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super(validate_all_val, self).__init__()\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.loss, self.acc = self.model.evaluate(val_batches, verbose=self.verbose)\n",
    "        print(' - all_val_accuracy: {0:.4f}'.format(self.acc))\n",
    "\n",
    "        pred = self.model.predict(val_batches)\n",
    "        label_pred = np.argmax(pred, axis=1)  \n",
    "\n",
    "        print('accuracy:', accuracy_score(pl_val_pd['label'], label_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dbed5b-011a-4920-98f0-29ae198995a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initially freeze all layers, train classification layer\n",
    "history = model.fit(train_batches,\n",
    "                    epochs=EPOCH_INITIAL,\n",
    "                    verbose=1,\n",
    "                    validation_data=val_batches,\n",
    "#                     callbacks=[early_stopping, csv_logger, validate_all_val()])\n",
    "                    callbacks=[early_stopping, csv_logger, save_per_epoch()])\n",
    "\n",
    "# # model.save('train_v1.1__01.h5')\n",
    "# print('Model saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef68b22f-8730-4381-b0ee-71f5c05dc5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tune the model for an additional 30 epochs, after the initial training phase\n",
    "EPOCH_FINE = 30\n",
    "EPOCH_TOTAL = EPOCH_INITIAL + EPOCH_FINE\n",
    "\n",
    "# if validation accuracy doesnâ€™t improve for 20 epochs, stop training and restore best weights.\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    verbose=1,\n",
    "    patience=20,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)\n",
    "\n",
    "csv_logger = tf.keras.callbacks.CSVLogger(os.path.join(path, 'log_fine_{}.csv'.format(FOLDER)), append=False)\n",
    "\n",
    "with strategy.scope():\n",
    "    # # unfreeze some top layers, fine tune\n",
    "    base_model.trainable = True\n",
    "\n",
    "    # (Optional) Fine-tune only top N layers\n",
    "    # fine_tune_at = 100\n",
    "    # for layer in base_model.layers[:fine_tune_at]:\n",
    "    #     layer.trainable = False\n",
    "\n",
    "    # Recompile model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-5),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f0be94-7cb6-4c57-a0a8-6f23bb169206",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_fine = model.fit(train_batches,\n",
    "                         epochs=EPOCH_TOTAL,\n",
    "                         verbose=1,\n",
    "                         initial_epoch=history.epoch[-1]+1,\n",
    "#                          initial_epoch=100,\n",
    "                         validation_data=val_batches,\n",
    "#                          callbacks=[early_stopping, csv_logger, validate_all_val()],\n",
    "                         callbacks=[early_stopping, csv_logger, save_per_epoch()])\n",
    "# # model.save('train_v1.1__02.h5')\n",
    "# print('Model saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd9b73c-109b-40d2-aae2-d8fee9559345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and load model\n",
    "\n",
    "# model.save('train_v2.1.h5')\n",
    "# print('Model saved.')\n",
    "\n",
    "# Load model with strategy.scope\n",
    "# https://www.tensorflow.org/tutorials/distribute/keras\n",
    "with strategy.scope():\n",
    "    model.load_weights(os.path.join(path, 'model_temp_{}_25.h5'.format(FOLDER)))\n",
    "    print(model.summary())\n",
    "# Load model without strategy.scope\n",
    "# model = tf.keras.models.load_model('train_v2.1_20_02.h5')\n",
    "# model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.00001),\n",
    "# #               loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6a4172-2ef2-4c5b-8928-da6ca672965b",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65762105-5372-4090-855a-d948576791d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc = history.history['accuracy']\n",
    "# val_acc = history.history['val_accuracy']\n",
    "# acc_fine = history_fine.history['accuracy']\n",
    "# val_acc_fine = history_fine.history['val_accuracy']\n",
    "\n",
    "# Load Accuracy Logs from CSV (Instead of Directly from history)\n",
    "acc = pd.read_csv(os.path.join(path, 'log_initial_{}.csv'.format(FOLDER)))['accuracy'].to_list()\n",
    "val_acc = pd.read_csv(os.path.join(path, 'log_initial_{}.csv'.format(FOLDER)))['val_accuracy'].to_list()\n",
    "acc_fine = pd.read_csv(os.path.join(path, 'log_fine_{}.csv'.format(FOLDER)))['accuracy'].to_list()\n",
    "val_acc_fine = pd.read_csv(os.path.join(path, 'log_fine_{}.csv'.format(FOLDER)))['val_accuracy'].to_list()\n",
    "\n",
    "# Plot Accuracy Curves FIRST\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(acc+acc_fine, label='Training Accuracy')\n",
    "plt.plot(val_acc+val_acc_fine, label='Validation Accuracy')\n",
    "plt.plot([EPOCH_INITIAL-1,EPOCH_INITIAL-1], plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "# Create directory and save AFTER plotting\n",
    "# root_path = '/Users/zhuangzhuang/Desktop/Data Science Project'\n",
    "root_path = '/home/featurize/results'\n",
    "\n",
    "accuracy_dir = os.path.join(root_path, 'Accuracy')\n",
    "os.makedirs(accuracy_dir, exist_ok=True)\n",
    "\n",
    "save_path = os.path.join(accuracy_dir, 'all.png')\n",
    "\n",
    "plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86654266-f428-49b4-a4c2-4607218c489f",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eca42d-41bf-4c59-9e1f-39abfd3bf53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3cbab4-f0a3-4146-85e6-29fa6705d60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Predict\n",
    "pred = model.predict(val_batches)\n",
    "label_pred = np.argmax(pred, axis=1)\n",
    "\n",
    "# Ground truth\n",
    "y_true = val_cell_info['label'].to_numpy()\n",
    "\n",
    "# Ensure correct label order\n",
    "labels = list(label2id.values())\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "# Confusion matrix\n",
    "cf_matrix = confusion_matrix(y_true, label_pred, labels=labels)\n",
    "\n",
    "# Output directory\n",
    "root_path = '/home/featurize/results/confusion_matrix'\n",
    "os.makedirs(root_path, exist_ok=True)\n",
    "\n",
    "# Plot and save\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cf_matrix,\n",
    "            annot=True,\n",
    "            fmt='d',\n",
    "            cmap='Blues',\n",
    "            xticklabels=[id2label[i] for i in labels],\n",
    "            yticklabels=[id2label[i] for i in labels],\n",
    "            linewidths=0.5)\n",
    "\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save to file\n",
    "save_path = os.path.join(root_path, 'all.png')\n",
    "plt.savefig(save_path, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Confusion matrix saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3236ea61-9377-492d-a850-da15368d639d",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62962a3d-b280-4bfa-93a7-7b172db655b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import platform\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "print('Python =', platform.python_version())\n",
    "print('TensorFlow =', tf.__version__)\n",
    "\n",
    "NUM_GPU = 4\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3'\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "CODE_FOLDER_NAME = 'codes'\n",
    "\n",
    "FOLDER = 'vall'\n",
    "\n",
    "BASE_PATH = 'All'\n",
    "\n",
    "# Recursively get all .png file paths\n",
    "all_png_paths = list(Path(BASE_PATH).rglob('*.png'))\n",
    "img_path_pd = pd.DataFrame(all_png_paths, columns=['path']).astype(str)\n",
    "\n",
    "# Extract base filename (no extension)\n",
    "img_path_pd['filename'] = img_path_pd['path'].apply(lambda x: os.path.splitext(os.path.basename(x))[0])\n",
    "\n",
    "# Save subfolder path\n",
    "img_path_pd['folder'] = img_path_pd['path'].apply(lambda x: str(Path(x).parent))\n",
    "\n",
    "# Extract \"front\" identifier (before \"-chX...\") \n",
    "# This will give r02c02f01p03-\n",
    "img_path_pd['front'] = img_path_pd['filename'].apply(lambda x: x.split('-')[0] + '-')\n",
    "\n",
    "# Parse metadata from filename\n",
    "img_path_pd['row']     = img_path_pd['filename'].str[0:3]    # e.g., r02\n",
    "img_path_pd['column']  = img_path_pd['filename'].str[3:6]    # e.g., c02\n",
    "img_path_pd['field']   = img_path_pd['filename'].str[6:9]    # e.g., f01\n",
    "img_path_pd['plane']   = img_path_pd['filename'].str[9:12]   # e.g., p03\n",
    "img_path_pd['channel'] = img_path_pd['filename'].str.split('-').str[1].str[:3]  # ch1\n",
    "img_path_pd['rcf']     = img_path_pd['row'] + img_path_pd['column'] + img_path_pd['field']\n",
    "img_path_pd['rc']      = img_path_pd['row'] + img_path_pd['column']\n",
    "\n",
    "# Extract cell number\n",
    "img_path_pd['cell_no_str'] = img_path_pd['filename'].str.extract(r'_Cell_(\\d{1,3})')[0]\n",
    "\n",
    "# === Extract plate_id from filename (_P1, _P2, _P3) ===\n",
    "# img_path_pd['plate_id'] = img_path_pd['filename'].str.extract(r'_P(\\d)$')[0].astype(int)\n",
    "img_path_pd['plate_id'] = img_path_pd['filename'].str.extract(r'_P(\\d)_F\\d')[0].astype(int)\n",
    "\n",
    "# Extract data factory (F123)\n",
    "img_path_pd['source'] = img_path_pd['filename'].str.extract(r'_F(\\d)$')[0].astype(int)\n",
    "\n",
    "\n",
    "# Convert column string to integer\n",
    "img_path_pd['column_id'] = img_path_pd['column'].str[1:].astype(int)\n",
    "\n",
    "# Map labels based on column number\n",
    "column_label_map = {\n",
    "    2: 'PARENT',\n",
    "    3: 'TREM2_KO',\n",
    "    4: 'R47H',\n",
    "    5: 'H157Y',\n",
    "    6: 'PLCG2_KO',\n",
    "    7: 'P522R',\n",
    "    8: 'P522R_HET',\n",
    "    9: 'SHIP1_KO',\n",
    "    10: 'ABI3_KO',\n",
    "    11: 'S209F'\n",
    "}\n",
    "img_path_pd['class_name'] = img_path_pd['column_id'].map(column_label_map)\n",
    "\n",
    "# Drop invalid rows\n",
    "img_path_pd = img_path_pd.dropna(subset=['class_name']).reset_index(drop=True)\n",
    "\n",
    "# Sort for consistency\n",
    "# img_path_pd = img_path_pd.sort_values(by=['rcf', 'plane', 'channel']).reset_index(drop=True)\n",
    "img_path_pd = img_path_pd.sort_values(by=['rcf', 'plane', 'channel', 'source']).reset_index(drop=True)\n",
    "\n",
    "print(img_path_pd.shape)\n",
    "img_path_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479b9cc7-5baf-441c-be2f-4629600c6575",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# control the label order\n",
    "custom_label_order = [\n",
    "    'PARENT', 'TREM2_KO', 'R47H', 'H157Y', 'PLCG2_KO',\n",
    "    'P522R', 'P522R_HET', 'SHIP1_KO', 'ABI3_KO', 'S209F'\n",
    "]\n",
    "\n",
    "# create name â†’ index mapping\n",
    "label2id = {name: idx for idx, name in enumerate(custom_label_order)}\n",
    "\n",
    "# Add a numerical label to the DataFrame\n",
    "img_path_pd['label'] = img_path_pd['class_name'].map(label2id)\n",
    "print('Custom label mapping: ', label2id)\n",
    "\n",
    "# Add a cell_id column\n",
    "# Create a unique cell_id using front + cell_no_str + plate_id\n",
    "#img_path_pd['cell_id'] = (\n",
    "#    img_path_pd['front'] + \n",
    "#    'Cell_' + img_path_pd['cell_no_str'] + \n",
    "#    '_P' + img_path_pd['plate_id'].astype(str)\n",
    "#)\n",
    "img_path_pd['cell_id'] = (\n",
    "    img_path_pd['front'] + \n",
    "    'Cell_' + img_path_pd['cell_no_str'] + \n",
    "    '_P' + img_path_pd['plate_id'].astype(str) +\n",
    "    '_F' + img_path_pd['source'].astype(str)\n",
    ")\n",
    "\n",
    "# Check whether each cell has all 5 channels\n",
    "cell_channel_counts = img_path_pd.groupby('cell_id')['channel'].count()\n",
    "print(f\"Cells with 5 channels: {(cell_channel_counts == 5).sum()}\")\n",
    "print(f\"Cells with incomplete channels: {(cell_channel_counts != 5).sum()}\")\n",
    "\n",
    "# Keep only cells with complete 5 channels\n",
    "complete_cells = cell_channel_counts[cell_channel_counts == 5].index\n",
    "img_path_pd_filtered = img_path_pd[img_path_pd['cell_id'].isin(complete_cells)].reset_index(drop=True)\n",
    "\n",
    "print(f\"Original cells: {img_path_pd['cell_id'].nunique()}\")\n",
    "print(f\"Complete cells: {len(complete_cells)}\")\n",
    "\n",
    "# Deduplicate based on cell_id, and create a label mapping for each cell\n",
    "cell_df = img_path_pd_filtered.drop_duplicates('cell_id')[['cell_id', 'label']]\n",
    "\n",
    "print(f\"Unique cells for splitting: {len(cell_df)}\")\n",
    "print(\"Label distribution:\")\n",
    "print(cell_df['label'].value_counts().sort_index())\n",
    "\n",
    "# Split the dataset by cells \n",
    "#train_cell_ids, val_cell_ids = train_test_split(\n",
    "#    cell_df['cell_id'],\n",
    "#    test_size=0.2,\n",
    "#    random_state=1,\n",
    "#    stratify=cell_df['label']\n",
    "#)\n",
    "cell_df['stratify_col'] = cell_df['label'].astype(str) + '_' + cell_df['cell_id'].str.extract(r'_F(\\d)$')[0]\n",
    "train_cell_ids, val_cell_ids = train_test_split(\n",
    "    cell_df['cell_id'],\n",
    "    test_size=0.2,\n",
    "    random_state=1,\n",
    "    stratify=cell_df['stratify_col']\n",
    ")\n",
    "\n",
    "# Retrieve the complete 5-channel image paths corresponding to each cell (image-level data)\n",
    "pl_train_pd = img_path_pd_filtered[img_path_pd_filtered['cell_id'].isin(train_cell_ids)].reset_index(drop=True)\n",
    "pl_val_pd = img_path_pd_filtered[img_path_pd_filtered['cell_id'].isin(val_cell_ids)].reset_index(drop=True)\n",
    "\n",
    "print(f'Training size: {pl_train_pd.shape}')\n",
    "print(f'Validation size: {pl_val_pd.shape}')\n",
    "print(f'Training unique cells: {pl_train_pd[\"cell_id\"].nunique()}')\n",
    "print(f'Validation unique cells: {pl_val_pd[\"cell_id\"].nunique()}')\n",
    "\n",
    "# Check the label distribution in the training and validation sets\n",
    "print(\"\\nTraining set label distribution:\")\n",
    "train_label_counts = pl_train_pd.drop_duplicates('cell_id')['label'].value_counts().sort_index()\n",
    "for label, count in train_label_counts.items():\n",
    "    class_name = [k for k, v in label2id.items() if v == label][0]\n",
    "    print(f\"  {class_name} (label {label}): {count} cells\")\n",
    "\n",
    "print(\"\\nValidation set label distribution:\")\n",
    "val_label_counts = pl_val_pd.drop_duplicates('cell_id')['label'].value_counts().sort_index()\n",
    "for label, count in val_label_counts.items():\n",
    "    class_name = [k for k, v in label2id.items() if v == label][0]\n",
    "    print(f\"  {class_name} (label {label}): {count} cells\")\n",
    "\n",
    "pl_train_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d747e1e3-a47b-4def-b91d-3188dfe52823",
   "metadata": {},
   "source": [
    "### Extract correctly predicted features only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b51bdc-33cc-4dbe-b94d-45c4d7641aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Predict on validation set\n",
    "pred_probs = model.predict(val_batches)\n",
    "label_pred = np.argmax(pred_probs, axis=1)\n",
    "\n",
    "# Ground truth labels (cell-level)\n",
    "y_true = val_cell_info['label'].to_numpy()\n",
    "\n",
    "# Find the indices of correctly predicted samples\n",
    "correct_indices = np.where(label_pred == y_true)[0]\n",
    "\n",
    "# Filter the information of correctly predicted cells (aligned with the order in val_batches)\n",
    "correct_val_info = val_cell_info.iloc[correct_indices].reset_index(drop=True)\n",
    "\n",
    "# Rebuild the Dataset to include only correctly predicted cells (add plate_id)\n",
    "#correct_fronts = correct_val_info['front'].to_numpy()\n",
    "#correct_cells  = correct_val_info['cell_no_str'].to_numpy()\n",
    "#correct_plates = correct_val_info['plate_id'].astype(str).to_numpy()\n",
    "#correct_labels = correct_val_info['label'].to_numpy()\n",
    "correct_fronts = correct_val_info['front'].to_numpy()\n",
    "correct_cells  = correct_val_info['cell_no_str'].to_numpy()\n",
    "correct_plates = correct_val_info['plate_id'].astype(str).to_numpy()\n",
    "correct_sources = correct_val_info['source'].astype(str).to_numpy()  \n",
    "correct_labels = correct_val_info['label'].to_numpy()\n",
    "\n",
    "# correct_ds = tf.data.Dataset.from_tensor_slices((correct_fronts, correct_cells, correct_plates, correct_labels))\n",
    "correct_ds = tf.data.Dataset.from_tensor_slices((correct_fronts, correct_cells, correct_plates, correct_sources, correct_labels))\n",
    "correct_batches = (\n",
    "    correct_ds\n",
    "    .map(stack_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "# extract features\n",
    "model_part = tf.keras.Model(\n",
    "    inputs=model.input,\n",
    "    outputs=model.get_layer('global_average_pooling2d').output  # ensure the layer name is correct\n",
    ")\n",
    "\n",
    "feature = model_part.predict(correct_batches)\n",
    "\n",
    "# Construct the feature DataFrame\n",
    "feature_pd = pd.DataFrame(\n",
    "    feature,\n",
    "    index=correct_val_info.index,\n",
    "    columns=('f_' + pd.Series(np.arange(feature.shape[1]).astype(str))).to_numpy()\n",
    ")\n",
    "\n",
    "# Merge with metadata\n",
    "feature_pd = pd.concat([feature_pd, correct_val_info], axis=1)\n",
    "\n",
    "\n",
    "feature_output_path = os.path.join(\n",
    "    '/home/featurize/features',\n",
    "    'all.csv'\n",
    ")\n",
    "\n",
    "os.makedirs(os.path.dirname(feature_output_path), exist_ok=True)\n",
    "\n",
    "feature_pd.to_csv(feature_output_path, index=False)\n",
    "\n",
    "print(f\"Feature extraction completed. Saved {feature_pd.shape[0]} correct samples to:\\n{feature_output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facaffaf-35fd-48d1-80ff-3fa036eadc3e",
   "metadata": {},
   "source": [
    "## similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7efb480-009d-4aa4-a003-5ef3598477c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "\n",
    "feature_csv_path = '/home/featurize/features/all.csv'\n",
    "output_dir = '/home/featurize/results/similarity'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "feature_pd = pd.read_csv(feature_csv_path)\n",
    "feature_columns = [col for col in feature_pd.columns if col.startswith('f_')]\n",
    "\n",
    "feature_pd = feature_pd.dropna(subset=['label'])  \n",
    "feature_pd[feature_columns] = feature_pd[feature_columns].apply(pd.to_numeric, errors='coerce').fillna(0.0)\n",
    "\n",
    "custom_label_order = [\n",
    "    'PARENT', 'TREM2_KO', 'R47H', 'H157Y', 'PLCG2_KO',\n",
    "    'P522R', 'P522R_HET', 'SHIP1_KO', 'ABI3_KO', 'S209F'\n",
    "]\n",
    "label2id = {name: idx for idx, name in enumerate(custom_label_order)}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "class_names = sorted(feature_pd['label'].unique())\n",
    "n_class = len(class_names)\n",
    "\n",
    "similarity_matrix = np.zeros((n_class, n_class))\n",
    "\n",
    "# Iterate over each pair of classes and compute the average sample-level pairwise similarity\n",
    "for i, label_i in enumerate(class_names):\n",
    "    feats_i = feature_pd[feature_pd['label'] == label_i][feature_columns].values\n",
    "    for j, label_j in enumerate(class_names):\n",
    "        if j < i:\n",
    "            similarity_matrix[i, j] = similarity_matrix[j, i]\n",
    "        else:\n",
    "            feats_j = feature_pd[feature_pd['label'] == label_j][feature_columns].values\n",
    "            sim_ij = cosine_similarity(feats_i, feats_j)\n",
    "            similarity_matrix[i, j] = np.mean(sim_ij)\n",
    "\n",
    "simi_df = pd.DataFrame(similarity_matrix, index=class_names, columns=class_names)\n",
    "\n",
    "if np.issubdtype(simi_df.index.dtype, np.integer):\n",
    "    simi_df.index = [id2label[i] if i in id2label else i for i in simi_df.index]\n",
    "    simi_df.columns = [id2label[i] if i in id2label else i for i in simi_df.columns]\n",
    "\n",
    "vmin = np.min(similarity_matrix)\n",
    "vmax = np.max(similarity_matrix)\n",
    "print(f\" Similarity range: min = {vmin:.4f}, max = {vmax:.4f}\")\n",
    "\n",
    "mask = np.triu(np.ones_like(simi_df, dtype=bool), k=1)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    simi_df,\n",
    "    mask=mask,\n",
    "    annot=True,\n",
    "    fmt='.4f',\n",
    "    cmap='Blues',\n",
    "    vmin=vmin,\n",
    "    vmax=vmax,\n",
    "    linewidths=0.5,\n",
    "    annot_kws={\"fontsize\": 8},\n",
    "    cbar_kws={'label': 'Cosine Similarity'}\n",
    ")\n",
    "plt.title(\"Similarity Matrix\", fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "simi_df.to_csv(os.path.join(output_dir, 'all.csv'))\n",
    "plt.savefig(os.path.join(output_dir, 'all.png'), dpi=300)\n",
    "\n",
    "print(\"Pairwise similarity matrix saved to:\", output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacc0203-9341-481d-ba46-e7ebf303b717",
   "metadata": {},
   "source": [
    "## UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5a4eae-415e-443e-98e7-5a82d8ba66f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "feature_csv_path = '/home/featurize/features/all.csv'\n",
    "output_dir = '/home/featurize/results/umap'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load features\n",
    "feature_pd = pd.read_csv(feature_csv_path)\n",
    "feature_columns = [col for col in feature_pd.columns if col.startswith('f_')]\n",
    "feature_pd = feature_pd.dropna(subset=['label'])  # drop rows without label\n",
    "\n",
    "# Standardize features\n",
    "features = feature_pd[feature_columns].fillna(0.0).astype(float)\n",
    "features_scaled = StandardScaler().fit_transform(features)\n",
    "\n",
    "# UMAP\n",
    "# reducer = umap.UMAP(n_neighbors=10, min_dist=0.5, metric='cosine', random_state=42)\n",
    "reducer = umap.UMAP(\n",
    "    n_neighbors=5,\n",
    "    min_dist=0.5,\n",
    "    metric='cosine',\n",
    "    random_state=42,\n",
    "    spread=1.5  \n",
    ")\n",
    "embedding = reducer.fit_transform(features_scaled)\n",
    "\n",
    "\n",
    "custom_label_order = [\n",
    "    'PARENT', 'TREM2_KO', 'R47H', 'H157Y', 'PLCG2_KO',\n",
    "    'P522R', 'P522R_HET', 'SHIP1_KO', 'ABI3_KO', 'S209F'\n",
    "]\n",
    "label2id = {name: idx for idx, name in enumerate(custom_label_order)}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "# Replace label with class name \n",
    "if np.issubdtype(feature_pd['label'].dtype, np.integer):\n",
    "    feature_pd['class_name'] = feature_pd['label'].map(id2label)\n",
    "else:\n",
    "    feature_pd['class_name'] = feature_pd['label']\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(\n",
    "    x=embedding[:, 0], y=embedding[:, 1],\n",
    "    hue=feature_pd['class_name'],\n",
    "    palette='tab10',\n",
    "    s=40,\n",
    "    edgecolor='none',\n",
    "    alpha=0.9\n",
    ")\n",
    "plt.title('UMAP projection of features', fontsize=14)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xlabel('UMAP-1')\n",
    "plt.ylabel('UMAP-2')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(output_dir, 'all_by_label.png'), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e243bbb3-b8f0-403c-8f05-b35c51e5e28e",
   "metadata": {},
   "source": [
    "## UMAP with plate id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa2aefb-1bd2-4214-b1c8-415e8cc8022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "feature_csv_path = '/home/featurize/features/all.csv'\n",
    "output_dir = '/home/featurize/results/umap'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load features\n",
    "feature_pd = pd.read_csv(feature_csv_path)\n",
    "feature_columns = [col for col in feature_pd.columns if col.startswith('f_')]\n",
    "feature_pd = feature_pd.dropna(subset=['plate_id'])  # drop rows without plate_id\n",
    "\n",
    "features = feature_pd[feature_columns].fillna(0.0).astype(float)\n",
    "features_scaled = StandardScaler().fit_transform(features)\n",
    "\n",
    "# UMAP \n",
    "#reducer = umap.UMAP(n_neighbors=5, min_dist=0.5, metric='cosine', random_state=42)\n",
    "reducer = umap.UMAP(\n",
    "    n_neighbors=5,\n",
    "    min_dist=0.5,\n",
    "    metric='cosine',\n",
    "    random_state=42,\n",
    "    spread=1.5  \n",
    ")\n",
    "embedding = reducer.fit_transform(features_scaled)\n",
    "\n",
    "# Process plate_id as a categorical label\n",
    "\n",
    "# Ensure plate_id is of string type for classification\n",
    "# feature_pd['plate_label'] = 'P' + feature_pd['plate_id'].astype(str)\n",
    "feature_pd['combined_label'] = 'F' + feature_pd['source'].astype(str) + '_P' + feature_pd['plate_id'].astype(str)\n",
    "\n",
    "# Define legend order\n",
    "\n",
    "# Create the desired order list\n",
    "desired_order = []\n",
    "for f in [1, 2, 3]:  # F1, F2, F3\n",
    "    for p in [1, 2, 3]:  # P1, P2, P3\n",
    "        desired_order.append(f'F{f}_P{p}')\n",
    "\n",
    "print(\"Desired order:\", desired_order)\n",
    "\n",
    "# Convert combined_label into an ordered categorical variable\n",
    "feature_pd['combined_label'] = pd.Categorical(\n",
    "    feature_pd['combined_label'], \n",
    "    categories=desired_order, \n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# Visulization\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(\n",
    "    x=embedding[:, 0], y=embedding[:, 1],\n",
    "    hue=feature_pd['combined_label'],\n",
    "    palette='Set1',\n",
    "    s=40,\n",
    "    edgecolor='none',\n",
    "    alpha=0.9\n",
    ")\n",
    "plt.title('UMAP projection of features (colored by Dataset_Plate)', fontsize=14)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', title='Dataset_Plate')\n",
    "plt.xlabel('UMAP-1')\n",
    "plt.ylabel('UMAP-2')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "#plt.figure(figsize=(10, 8))\n",
    "#sns.scatterplot(\n",
    "#    x=embedding[:, 0], y=embedding[:, 1],\n",
    "#    hue=feature_pd['combined_label'],\n",
    "#    palette='Set1',  \n",
    "#    s=40,\n",
    "#    edgecolor='none',\n",
    "#    alpha=0.9\n",
    "#)\n",
    "#plt.title('UMAP projection of features', fontsize=14)\n",
    "#plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', title='Plate ID')\n",
    "#plt.xlabel('UMAP-1')\n",
    "#plt.ylabel('UMAP-2')\n",
    "#plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(output_dir, 'all_by_plate.png'), dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Distribution of Output\n",
    "#print(\"Plate distribution in the data:\")\n",
    "#plate_counts = feature_pd['plate_label'].value_counts().sort_index()\n",
    "#for plate, count in plate_counts.items():\n",
    "#    print(f\"  {plate}: {count} samples\")\n",
    "\n",
    "print(\"Dataset-Plate distribution in the data:\")\n",
    "combined_counts = feature_pd['combined_label'].value_counts().sort_index()\n",
    "for label, count in combined_counts.items():\n",
    "    print(f\"  {label}: {count} samples\")\n",
    "\n",
    "print(f\"Total samples: {len(feature_pd)}\")\n",
    "print(f\"Number of plates: {len(plate_counts)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
